{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)\n",
    "\n",
    "Support Vector Machines (SVM) are a powerful class of supervised machine learning algorithms used for both classification and regression tasks. They aim to find the optimal hyperplane that maximizes the margin between different classes in the feature space.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Hyperplane\n",
    "\n",
    "- A hyperplane is a decision boundary that separates data points of different classes in feature space. In 2D, it's a line; in 3D, it's a plane; and in higher dimensions, it's a hyperplane.\n",
    "\n",
    "### Margin\n",
    "\n",
    "- The margin is the distance between the hyperplane and the nearest data point of any class. SVM aims to maximize this margin, which represents the degree of separation between classes.\n",
    "\n",
    "### Support Vectors\n",
    "\n",
    "- Support vectors are the data points that lie closest to the hyperplane and influence the positioning of the hyperplane. They are critical for defining the margin.\n",
    "\n",
    "### Classification\n",
    "\n",
    "- SVM performs classification by finding the hyperplane that maximizes the margin while maintaining a trade-off with classification errors.\n",
    "\n",
    "### Soft Margin\n",
    "\n",
    "- In cases where perfect separation is not possible, a soft margin SVM allows for a certain number of misclassifications to be made. The regularization parameter \"C\" controls the softness of the margin.\n",
    "\n",
    "## SVM Formulation\n",
    "\n",
    "SVM finds the optimal hyperplane by solving a mathematical optimization problem. In the case of linearly separable data, the objective function is:\n",
    "\n",
    "Minimize: 0.5 * ||w||^2\n",
    "\n",
    "Subject to: y_i * (w * x_i + b) >= 1 for all data points\n",
    "\n",
    "Here:\n",
    "- \"w\" is the weight vector.\n",
    "- \"b\" is the bias term.\n",
    "- \"x_i\" is the feature vector.\n",
    "- \"y_i\" is the class label (either 1 or -1).\n",
    "\n",
    "## Kernel Trick\n",
    "\n",
    "SVM can handle non-linearly separable data by transforming it into a higher-dimensional feature space. The kernel trick is a technique used to compute dot products in this high-dimensional space efficiently.\n",
    "\n",
    "Common kernels include the linear, polynomial, radial basis function (RBF), and sigmoid kernels.\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "- **C (Regularization Parameter)**: Controls the trade-off between maximizing the margin and minimizing classification errors. Larger \"C\" values lead to a narrower margin with fewer errors, while smaller values prioritize a wider margin with more errors.\n",
    "\n",
    "- **Kernel Choice**: The choice of kernel function determines the transformation used to create the high-dimensional feature space.\n",
    "\n",
    "- **Kernel Parameters**: Some kernels, such as the RBF kernel, have additional parameters like \"gamma\" that control the shape and complexity of the decision boundary.\n",
    "\n",
    "## Training and Predictions\n",
    "\n",
    "1. Select a kernel and set hyperparameters.\n",
    "2. Train the SVM on labeled data.\n",
    "3. Use the trained SVM for classification of new data points.\n",
    "\n",
    "## Pros and Cons\n",
    "\n",
    "**Pros**:\n",
    "- Effective for high-dimensional data.\n",
    "- Can handle non-linearly separable data.\n",
    "- Provides robustness against overfitting (with appropriate \"C\" values).\n",
    "\n",
    "**Cons**:\n",
    "- Sensitive to the choice of kernel and hyperparameters.\n",
    "- Can be computationally expensive for large datasets.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Support Vector Machines are versatile and powerful tools for classification tasks. Understanding the fundamental concepts and tuning hyperparameters is essential for effective use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
